% Created 2021-05-26 Wed 11:59
% Intended LaTeX compiler: pdflatex
\documentclass{amsart}
\usepackage{enumerate}
\usepackage{amsthm,amscd,amssymb,verbatim,epsf,amsmath,amsfonts,mathrsfs,graphicx}
\usepackage[linktocpage,colorlinks=true,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{lineno}
% The bibliography file
% Theorem Environment.
\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem{prob}{Problem}
\newtheorem{cor}{Corollary}
\newtheorem{mydef}{Definition}
\newtheorem{conj}{Conjecture}

% Here some definitions of operators
% Trace operator.
\DeclareMathOperator{\tr}{tr}
% Divergence Operator.
\DeclareMathOperator{\diver}{div}
% Index of an  Operator.
\DeclareMathOperator{\ind}{ind}
% Diameter.
\DeclareMathOperator{\diamm}{diam}
% Inverse of hyperbolic tan
\DeclareMathOperator\artanh{artanh}
% Distance
\DeclareMathOperator{\dist}{dist}
% Scalar Curvature
\DeclareMathOperator{\R}{dist}
% Ricci Curvature
\DeclareMathOperator{\Ric}{Ric}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\author{Daniel Ballesteros Chávez}
\date{\textit{<2021-03-12 Fri>}}
\title{Lecture notes for Sel. Topics Calc. Several Variables.}
\hypersetup{
 pdfauthor={Daniel Ballesteros Chávez},
 pdftitle={Lecture notes for Sel. Topics Calc. Several Variables.},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.1 (Org mode 9.3.6)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents




\section{Some subsets of the Euclidean Space}
\label{sec:org1bfd0bf}

We have defined for \(r>0\) the open ball centred at \(x_0\in \mathbb{R}^n\) as
\[ B_r(x_0) = \{ x \in \mathbb{R}^n \, | \, |x - x_0| < r,\}\]
and if \(x_0\) is the origin we simply write \(B_r\).



Given a set \(A\subset \mathbb{R}^n\), then we can distinguish three possibilities for any \(x\in \mathbb{R}^n\):
\begin{enumerate}
\item \(x\) is an interior point of \(A\): There exists \(r>0\) such that \(B_r(x) \subset A\).
\item \(x\) is an exterior point of \(A\): There exists \(r>0\) such that \(B_r(x) \subset \mathbb{R}^n \setminus A\).
\item \(x\) is a boundary point of \(A\): For every \(r>0\) it holds \(B_r(x) \cap A \neq \emptyset\) and \(B_r(x)\cap (\mathbb{R}^n \setminus A)\neq \emptyset\)
\end{enumerate}



Now we can also define certain basic sets in \(\mathbb{R}^n\):
\begin{itemize}
\item A set \(U\subset \mathbb{R}^n\) is called open if every \(x\in U\) is an interior point.
\item A set \(F\subset \mathbb{R}^n\) is called closed if its complement \(\mathbb{R}^n\setminus F\) is open.
\item A set \(A\subset \mathbb{R}^n\) is said to be bounded if there is a \(r_0>0\) such that \(A\subset B_{r_0}\).
\item A set \(K\subset \mathbb{R}^n\) is called compact if it is closed and bounded.
\end{itemize}


\section{Maps between \(\mathbb{R}^n\) and \(\mathbb{R}^m\).}
\label{sec:org836fcee}

In this section we will list definitions and establish some notation and terminology regarding the maps between to Euclidean spaces.

\begin{enumerate}
\item A map \(f : \mathbb{R}^n \to \mathbb{R}^m\) is a rule which associates to each point  \(x\in \mathbb{R}^n\) some point in \(\mathbb{R}^m\)  denoted by \(f(x)\).

\item If \(A\subset \mathbb{R}^n\) then \(f : A \to \mathbb{R}^m\) means that \(f\) is just defined for \(x\in A\) and we say that \(A\) is the domain of \(f\).

\item If \(B \subset A\), we define the image of \(B\) under the map \(f\) as the set of all \(f(x)\in\mathbb{R}^m\) for \(x\in B\).

\item If \(C \subset \mathbb{R}^m\) we define the inverse image of \(C\) under \(f\) as the subset of \(\mathbb{R}^n\) given by \(f^{-1}(C) = \{ x\in \mathbb{R}^n \,|\, f(x) \in C\}\).

\item The notation \(f:A\to B\) always means that \(f(A)\subseteq B\).

\item Whenever  \(B\subseteq \mathbb{R}\) we called \(f\) a function.

\item If \(f,g:\mathbb{R}^n \to \mathbb{R}\) are two functions then the functions \(f + g\), \(f\cdot g\) and \(f/g\) are defined pointwise as in the one-variable case.

\item Let \(A\subseteq \mathbb{R}^n\) and \(B\subseteq\mathbb{R}^m\). If \(f:A\to \mathbb{R}^m\) and \(g: B\to \mathbb{R}^l\) the compostion \((g \circ f)\) is the function defined by \((g\circ f)(x) = g(f(x))\). Note that the domain of definition of the composition map is \(A\cap f^{-1}(B)\).

\item A map \(f:A\to \mathbb{R}^m\) is said to be injective or one to one (1-1) if it holds that \(f(x) = f(y)\) if and only if \(x = y\).

\item whenever \(f\) is injective we define its inverse \(f^{-1}: f(A) \to \mathbb{R}^n\) by associating \(f^{-1}(z)\) to the unique \(x\in A\) such that \(f(x)=z\).

\item Any map \(f:A \to \mathbb{R}^m\) determines and it is determined by the so called component functions \(f_i:A\to \mathbb{R}\), \(i=1,2,\ldots,m\) by the equality \(f(x) = (f_1(x),f_2(x),\ldots, f_m(x))\).

\item The identity map \(\mbox{id}:\mathbb{R}^n\to \mathbb{R}^n\), \(\mbox{id}(x) = x\).

\item For \(1\leq i \leq n\), the projection on the \(i\) -th coordinate is the function \(\pi_i: \mathbb{R}^n \to \mathbb{R}\) such that \(\pi_i(x) = x_i\).
\end{enumerate}



\section{Limits and Continuity}
\label{sec:org1083ae7}

As in the case of real analysis (or any metric space) we define the limit \[ \lim_{x \to a} f(x) = b,\] by requiring that for every \(\epsilon >0\) there is a number \(\delta >0\) such that \(|f(x) - b| < \epsilon\) for every \(x\) in the domain of \(f\) such that \(|x-a| < \delta\).

If \(f:A\to \mathbb{R}^m\) is such that \[\lim_{x\to a} f(x) = f(a),\] then we say that \(f\) is continuous at \(a\). If \(f\) is continuous at every \(a\in A\) then \(f\) is simply called continuous.


Continuity of a map can be determined in terms of open subsets. Here there is a list of basic properties

\begin{enumerate}
\item A map \(f:\mathbb{R}^n\to\mathbb{R}^m\) is continuous if and only if for every open subset of \(U\subset\mathbb{R}^m\) then inverse image \(f^{-1}(U)\) is an open subset of \(\mathbb{R}^n\).
\item If \(A\subset \mathbb{R}^n\), then a map \(f:A\to\mathbb{R}^m\) is continuous if and only if for every open subset of \(U\subset\mathbb{R}^m\)  there is an open set \(V\in\mathbb{R}^n\) such that \(f^{-1}(U)= V \cap A\).
\item If \(K\subset \mathbb{R}^n\) is compact and  \(f: K \to \mathbb{R}^m\) is continuous then the direct image \(f(K)\) is a compact subset of \(\mathbb{R}^m\).
\item For \(f:\mathbb{R}^n\to \mathbb{R}^m\), then \(\lim_{x\to a}f(x) = b\) if and only if \(\lim_{x\to a}f_i(x) = b_i\) for \(i= 1,2,\ldots m\).
\item The map \(f:\mathbb{R}^n \to \mathbb{R}^m\) is continuous if and only if \(f_i:\mathbb{R}^n\to\mathbb{R}\) are continuous, for all \(i=1,2,\ldots m\).
\end{enumerate}


\section{Derivatives}
\label{sec:orgdf52a30}

\begin{mydef}
A map \(f:\mathbb{R}^n \to \mathbb{R}^m\) is differentiable at \(a\in \mathbb{R}^n\) if there is a linear transformation \(Df_a: \mathbb{R}^n \to \mathbb{R}^m\) such that
\[ \lim_{h\to 0} \frac{|f(a + h) - f(a) - Df_a(h)|}{|h|} = 0. \]
\end{mydef}

In order to understand this linear transformation we introduce partial derivatives for a function \(f: \mathbb{R}^n \to \mathbb{R}\) at \(a \in \mathbb{R}^n\) as the limit
\[ \frac{\partial f(a)}{\partial x_i} = \lim_{h\to 0} \frac{f(a_1,a_2,\ldots, a_i + h, \ldots, a_n) - f(a_1,\ldots, a_n)}{h}.\]

Then it is possible to prove that for any map \(f:\mathbb{R}^n \to \mathbb{R}^m\), the matrix representing the linear transformation \(Df_a\) is 
\[ (Df_a) = \left( \begin{array}{ccc}
\frac{\partial f_1(a)}{\partial x_1} & \cdots & \frac{\partial f_1(a)}{\partial x_n}\\
\vdots & \vdots & \vdots  \\
\frac{\partial f_m(a)}{\partial x_1} & \cdots & \frac{\partial f_m(a)}{\partial x_n}\\
\end{array} \right). \]

\textbf{Remark} Note that \((Df_a)\)  is a matrix with \(m\) rows and \(n\) columns.



The Chain rule: Let \(f:\mathbb{R}^n \to \mathbb{R}^m\) and \(g: \mathbb{R}^m \to \mathbb{R}^l\) such that the composition 
\((g\circ f) : \mathbb{R}^n \to \mathbb{R}^l\) is well defined. If \(f\) and \(g\) are differentiable then for any \(a\in \mathbb{R}^n\) we have
\[D(g\circ f)_a = Dg_{f(a)} \circ Df_a. \] 

Second order partial derivatives will be denoted by
\[\frac{ \partial^2 f}{\partial x_i^2} = \frac{\partial}{\partial x_i}\left( \frac{\partial f}{\partial x_i}\right) \]
\[\frac{ \partial^2 f}{\partial x_j \partial x_i} = \frac{\partial}{\partial x_j}\left( \frac{\partial f}{\partial x_i}\right) \]

If all mixed second order partial derivatives are continuous at a point or on a set, \(f\) is called a \(C^2\) function at that point (or on that set); in this case, the order of the partial derivatives can be interchanged
\[ \frac{\partial^2 f}{\partial x_j \partial x_i} = \frac{\partial^2 f}{\partial x_i \partial x_j}\]

Example:

\[{\displaystyle f(x,\,y)={\begin{cases}{\frac {xy\left(x^{2}-y^{2}\right)}{x^{2}+y^{2}}}&{\mbox{ for }}(x,\,y)\neq (0,\,0),\\0&{\mbox{ for }}(x,\,y)=(0,\,0).\end{cases}}}\]



\section{Differential Geometry of Curves}
\label{sec:org899d111}

\subsection{Curves in \(\mathbb{R}^3\)}
\label{sec:orgea00c22}

\begin{mydef}
A \textbf{parameterised differentiable curve} is a map \(\alpha: I \to \mathbb{R}^3\), where
\(I= (a,b)\) is an open interval of the real line.
\end{mydef}

\textbf{Remarks}. The curve \(\alpha\) is defined by three real functions:
\[ \alpha(t) = \left(x(t), y(t), z(t) \right). \]
The variable \(t\) is called the parameter of the curve.
The interval \(I\) could also be the real line \(\mathbb{R}\).
The trace of the curve is the image \(\alpha(I) \subset \mathbb{R}^3\).

For the derivative of the map \(\alpha\) with respect to the parameter \(t\) at any \(t_0\in I\),
we may use one of the several available notations
\begin{itemize}
\item \(\left.\dfrac{d\alpha}{dt}\right|_{t=t_0}\).
\item \(\alpha'(t_0)\)
\item \(\dot\alpha(t_0)\).
\end{itemize}
and we have
\[ \alpha'(t) = (x'(t), y'(t), z'(t)) . \]

This is called the \textbf{velocity vector} or the \textbf{tangent vector} of the curve \(\alpha\) at \(t\).



\begin{prop}
If \(\alpha,\beta:I\to \mathbb{R}^3\) are two differentiable curves, then \(\alpha(t) \bullet \beta(t)\) is a differentiable function and 
\[\frac{d}{dt} \left( \alpha(t)\bullet \beta(t) \right) = \alpha'(t)\bullet \beta(t) + \alpha(t)\bullet \beta'(t). \]
\end{prop}

\begin{prop}
If \(\alpha,\beta:I\to \mathbb{R}^3\) are two differentiable curves, then \(\alpha(t) \times \beta(t)\) is a differentiable map and 
\[\frac{d}{dt} \left( \alpha(t)\times \beta(t) \right) = \alpha'(t)\times \beta(t) + \alpha(t)\times \beta'(t). \]
\end{prop}



\begin{mydef}
Let \(\alpha:I \to \mathbb{R}^3\) be a parameterised differentiable curve. 
\begin{enumerate}
\item A \textbf{singular point} of \(\alpha\) is any \(t\in I\) such that \(\alpha'(t) = 0\).
\item If \(\alpha'(t) \neq 0\) for every \(t\in I\), then we say that \(\alpha\) is a \textbf{regular curve}.
\end{enumerate}
\end{mydef}

\begin{prop}
Let \(\alpha : I\to \mathbb{R}^3\) be a parameterised regular curve. Show that \(|\alpha(t)|\) is a non-zero constant if and only if \(\alpha(t)\) is orthogonal to \(\alpha'(t)\) for all \(t\in I\).
\end{prop}
\begin{proof}
It follows easily from last proposition and
\[ 0 < c^2 = |\alpha|^2 \Leftrightarrow 0 = \frac{d}{dt} |\alpha(t)|^2 = 2 \alpha(t)\bullet \alpha'(t) \Leftrightarrow \alpha(t) \perp \alpha'(t).\]
\end{proof}


\begin{mydef}
Given \(t \in I\), the \textbf{arc-length} of a regular parameterised curve \(\alpha: I \to \mathbb{R}^3\) from the point \(t_0\) is \[ s(t) = \int_{t_0}^{t} |\alpha'(r)| dr. \]
\end{mydef}

\begin{mydef}
If the parameter \(t\) of a curve \(\alpha\) is already the arc-length measured from some point,
we say that \(\alpha\) is parameterised by arc length and in this case we usually write \(\alpha(s)\).
\end{mydef}

\begin{prop}
The arc-length \(s(t)\) is a differentiable function. If in addition the curve \(\alpha\) is regular, i.e., \(\alpha'(t) \neq 0\) for all \(t \in I\), it also holds that \(s'(t) >0\), hence \(s(t)\) has a continuous inverse \(s^{-1}(r)\).
\end{prop}
\begin{proof}
Recall

\textbf{First Fundamental theorem of Calculus}. Let \(f\) be a continuous real-valued function defined on a closed interval \([a, b]\). Let \(F\) be the function defined, for all \(x \in [a, b]\), by
\[    F(x)=\int _{a}^{x}\!f(t)\,dt.\]
Then \(F\) is uniformly continuous on \([a, b]\) and differentiable on the open interval \((a, b)\), and
\[ F'(x)=f(x)\,, \mbox{for all } x \in (a, b). \]

For \([t_0,t]\subset I\), the map \(\alpha: [t_0,t] \to \mathbb{R}^3\) is smooth (differentiable) which implies that  \(\alpha': [t_0,t] \to \mathbb{R}^3\) is continuous.  Since \(|\cdot|:\mathbb{R}^3 \to \mathbb{R}\) is also continuous,  the composition \(t \to |\alpha'(t)|\) is also continuous. Then by the Fundamental Theorem of Calculus, \(s(t)\) is differentiable.
For the second part, note that since \(\alpha'(t) \neq 0\) we have
\[ \frac{ds(t)}{dt} = |\alpha'(t)| >0 .\]
Finally recall that any a continuous (differentiable) strictly monotone function defined on an interval has an inverse which is also a continuous (differentiable) function.
\end{proof}

\begin{prop}
The curve \(\alpha\) is parameterised by arc-length if and only if its velocity vector has constant length equal to 1.
\end{prop}
\begin{proof}
(\(\Rightarrow\)) If the parameter \(t = s(t)\), then we have (form the proof the previous proposition)
\[ 1 = \frac{ds}{dt} = |\alpha'(t)|. \]
(\(\Leftarrow\)) Assuming that \(|\alpha'(t)| =1\) for all \(t \in I\), it follows that
\[ s(t) = \int_{t_0}^{t}|\alpha'(r)|dr = \int_{t_0}^{t}dr = t - t_0,\]
then \(t\) is the arc-length of \(\alpha\) measured from some point.
\end{proof}

\begin{mydef}
Let \(\alpha : I \to  \mathbb{R}^3\) be a parameterised curve. We call the curve \(\beta : J \to \mathbb{R}^3\) a reparameterisation of \(\alpha\), is there is
a differentiable bijective function \(u: J\to I\) with inverse \(u^{-1}:I\to J\) also differentiable and 
\[ \beta (r) = (\alpha \circ u) (r), \mbox{ for all }\, r\in J. \]
\end{mydef}


\begin{prop}
Given a regular parameterised curve \(\alpha : I \to \mathbb{R}^3\), it is possible to obtain 
a curve \(\beta : J \to \mathbb{R}^3\) parameterised by arc-length which has the same trace as \(\alpha\).
\end{prop}

\begin{proof}
Let \(s(t) = \int_{t_0}^{t} |\alpha'(r)|dr\), with \(t_0,t\in I\). Since \(\alpha\) is regular we already noticed that
\(\frac{ds}{dt} = |\alpha'(t)| >0\) and then the function \(s(t)\) has a differentiable inverse \(g(s)\), where \(s\in s(I) = J\). Moreover from the chain rule we have
\[ t = g(s(t)) \Rightarrow 1 = \frac{d g(s)}{ds} \frac{ds(t)}{dt} = \frac{d g(s)}{ds} |\alpha'(t)|.\]

Now, set \(\beta(s) = (\alpha \circ g) (s)\). Since clearly \(\beta(J) = \alpha(I)\), they have the same trace.
Note now that by the chain rule 
\[ \left|\beta'(s)\right| = \left|\frac{d\beta (s)}{ds} \right| = \left| \frac{d\alpha (g(s))}{dt} \frac{d g(s)}{ds} \right| = \left| \frac{d\alpha (t)}{dt}\right|\, \left| \frac{dg(s)}{ds} \right| = \left|\alpha'(t)\right| \frac{1}{|\alpha'(t)|} = 1. \]
Then, from the previous proposition, \(\beta\) is parameterised by arc-length.
\end{proof}

\textbf{Remark} The curve \(\beta\) constructed in the last proposition is called an \textbf{arc-length re-parameterisation} of \(\alpha\) by arc-length, or equivalently, a \textbf{unit speed reparametersia tion}.

\begin{mydef}
Given a curve \(\alpha\) parameterised by arc-length \(s\in (a,b)\), the curve \(\beta\) defined in the interval \((-b, -a)\), \(\beta(-s) = \alpha(s)\) is said to be a change of orientation of \(\alpha\).
\end{mydef}


\subsection{Examples.}
\label{sec:orge38cd07}

\begin{enumerate}
\item Find the trace and the tangent vectors of the following curves
\begin{enumerate}
\item \(\alpha(t)  = (a \cos t, a \sin t, b\,t)\).
\item \(\alpha(t)  = ( t^3, t^2)\).
\item \(\alpha(t)  = (t^3 -4t, t^2 -4)\).
\item \(\alpha(t)  = (t, |t|)\).
\item \(\alpha(t)  = (\cos t, \sin t)\).
\item \(\alpha(t)  = (\cos 2t, \sin 2t)\).
\end{enumerate}

\item Find the arc-length parameterisation of the following curves if possible:

\begin{enumerate}
\item \(\alpha(t)  = (\cos 2t, \sin 2t)\), for \(0 < t < 2\pi\)

\item \(\alpha(t) = (t, t^2, t^3)\), for \(-\infty < t < \infty\).
\end{enumerate}
\end{enumerate}



\begin{verbatim}
TT <- seq(-10,10,length.out=100)
AA <- 1
BB <- 1
jpeg("ex2.jpg")
plot(TT^3,TT^2,type="l")
dev.off()
\end{verbatim}
\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{img.jpg}
\caption{\(\alpha(t)  = ( t^3, t^2)\)}
\end{figure}







\subsection{The Local theory of Curves}
\label{sec:orgb95a1d5}

\begin{mydef}
Let \(\alpha : I \to \mathbb{R}^3\) be a curve parameterised by arc-length. The curvature of \(\alpha\) at \(s\) is defined by
\[ \kappa(s) = |\alpha''(s)| . \]
\end{mydef}



Note that if \(\alpha(s) = As + B\), with \(A,B\in \mathbb{R}^3\) fixed vectors, and \(|A|=1\). Then \(\kappa(s) = 0\). 

If we start by assuming that \(\kappa(s) = 0\), then \(\alpha''(s) = 0\) for all \(s\in I\). Then by integrating each of the coordinate functions, and after reparamaterising by arch length if necessary, one can write \(\alpha(s) = As + B\).

\emph{This makes sense with our intuition that a straight line has no curvature.}

Notice that when \(\alpha\) is parameterised by arc-length, the length of the tangent vector \(|\alpha'(s)|=1\) remains constant. The curvature then measures the rate of change of the angle between tangent vectors at each point on the curve \(\alpha(s)\).


\begin{prop}
For \(\alpha(s)\), the vector \(\alpha''(s)\) and the curvature \(\kappa(s)\) remain invariant (unchanged) under a change of orientation.
\end{prop}
\begin{proof}
Let \(\beta(-s) = \alpha(s)\) a change of orientation. Put \(r = -s\), then \(ds/dr = -1\), and hence by the chain rule
\[ \frac{d\beta(r)}{dr} = \frac{d\alpha(s)}{dr} = \frac{d\alpha}{ds}\frac{ds}{dr} = -\frac{d\alpha}{ds}. \]
Differentiating a second time we get

\[ \beta''(r) = \frac{d^2\beta(r)}{dr^2}   = -\frac{d}{dr}\frac{d\alpha}{ds} = -\frac{d^2\alpha}{ds^2} \frac{ds}{dr} = \frac{d^2\alpha}{ds^2} = \alpha''(s), \]
as we wished to show.
\end{proof}

\textbf{Important} In what follows it will be essential to assume that the curves we will be working with are parameterised by arc-length, regular and such that \(\alpha'(s)\) have no singular points (\(\alpha''(s)\neq 0\)).

\begin{mydef}
At points where \(\kappa(s) \neq 0\), we define the following unit vectors
\begin{itemize}
\item The tangent vector at s: \(T(s) = \alpha'(s)\).
\item The (principal) normal vector at s: \(N(s) = \frac{1}{\kappa(s)} \alpha''(s)\)
\item The binormal vector at s: \(B(s) = T(s) \times N(s)\).
\end{itemize}
\end{mydef}


\begin{prop}
For a curve \(\alpha(s)\) there is a function \(\tau(s)\) called the \textbf{torsion} of \(\alpha\) at \(s\), such that
\begin{itemize}
\item \(T'(s) = \kappa(s) N(s)\).
\item \(N'(s) = -\kappa(s) T(s) - \tau(s) B(s)\).
\item \(B'(s) = \tau(s) N(s)\) .
\end{itemize}

This are called the \textbf{Frenet's equations}.
\end{prop}

\begin{proof}


The evaluation at \(s\) will be written when necessary.

We have \(T' = \kappa\,N\) holds by definition.

Note that \(B = T \times N\) is also a unit vector. Then \(B' \perp B\). By properties of the cross product
\[ B' = T' \times N  + T \times N'  = T \times N',\]
where the first term vanishes because \(T'\) and \(N\) are linearly dependent.

From the last identity we can say that \(B'\) is perpendicular to \(T\), moreover, \(B'\) must be a multiple of \(N\). Then at each point we can write
\[ B'(s) = \tau(s) N(s). \]

Since at each value of the parameter \(s\) we have the basis \(\{ T, N, B\}\), we can write \(N = B \times T\) and it follows 
\[ N' = B' \times T + B \times T' = \tau\, N \times T + B \times \kappa \, N = - \tau \, B - \kappa\, T \]
\end{proof}



\begin{thm}
Given differentiable functions \(\kappa(s)>0\) and \(\tau(s)\) defined in an open interval \(s\in I\), there exists 
a regular parameterised curve \(\alpha : I\to \mathbb{R}^3\) such that
\begin{itemize}
\item \(s\) is the arch length of \(\alpha\).
\item \(\kappa(s)\) is the curvature.
\item \(\tau(s)\) is the torsion.
\end{itemize}

Additionally, if \(\bar{\alpha}\) is another curve satisfying the same conditions, then it differs from \(\alpha\) by a rigid motion, i.e. there is an orthogonal linear map \(A:\mathbb{R}^3 \to \mathbb{R}^3\) with positive determinant, and a vector \(C\in \mathbb{R}^3\) such that
\[\bar{\alpha} = A\alpha + C \]
\end{thm}
\begin{proof}
Proof of Existence.

Note first that the Frenet's equations define a system of differential equations in \(I\times \mathbb{R}^9\). By letting \(T = (x_1,x_2,x_3),N = (x_4,x_5,x_6),B = (x_7,x_8,x_9)\) and linear functions \(f_i = f_i(s,x_1,\ldots, x_9)\) in \(x_i's\) with coefficients depending on \(s\).
\[
\left\{ \begin{array}{ccc}
\frac{dx_1}{dt} & = & f_1(s,x_1,\ldots,x_9)\\
\vdots & \vdots & \vdots  \\
\frac{dx_9}{dt} & = & f_9(s,x_1,\ldots,x_9)
\end{array} \right. \]

A theorem of existence and uniqueness holds in the following form. Given initial conditions \(s_0\in I\), \(x_{1_0}, \ldots x_{9_0}\), there exists an open interval \(J\subset I\) containing \(s_0\), and a unique differentiable map \(\varphi : J \to \mathbb{R}^9\) with
\[ \varphi(s_0) = (x_{1_0}, \ldots x_{9_0}), \quad \mbox{and} \quad \varphi'(s) = (f_1,\ldots f_9), \]
where the \(f_i's\) are defined in \((s,\varphi(s)) \in J \times \mathbb{R}^9\). And moreover, for linear systems \(J = I\).

In other words, applying the theorem of existence and uniqueness for linear systems of linear equations we can prove that given a positively oriented set of orthonornal vectors \(\{T_0,N_0,B_0\}\) in \(\mathbb{R}^3\)
and a value \(s_0\in I\), there is a family of vectors \(\{ T(s) , N(s), B(s) \}\), \(s\in I\) with \(T(s_0) = T_0, N(s_0) = N_0, B(s_0) = B_0\).

The family thus obtained \(\{T(s), N(s), B(s) \}\) remains orthonormal for every \(s\in I\). To show this we use again the Frenet's equations in combination with the inner product. For more clarity we write \(A\bullet B = \langle A, B \rangle\).
\begin{equation}
\begin{array}{rcl}
\frac{d}{ds}\langle T,N\rangle & = & \kappa \langle N, N \rangle - \kappa \langle T, T, \rangle - \tau \langle T, B\rangle\\
\frac{d}{ds}\langle T,B\rangle & = & \kappa \langle N, B \rangle + \tau \langle T, N\rangle\\
\frac{d}{ds}\langle N,B\rangle & = & -\kappa \langle T, B \rangle - \tau \langle B, B, \rangle + \tau \langle N, N\rangle\\
\frac{d}{ds}\langle T,T\rangle & = & 2\kappa \langle T, N \rangle \\
\frac{d}{ds}\langle N,N\rangle & = & -2\kappa \langle N, T \rangle  - 2 \tau \langle N, B\rangle\\
\frac{d}{ds}\langle B,B\rangle & = & 2 \tau \langle B, N\rangle
\end{array}
\end{equation}
One can check that a solution of the above system of equation is

\begin{equation}
\begin{split}
y_1 = \langle T, N \rangle \equiv 0, \quad y_1 (s_0)= 0\\
y_2 = \langle B, B \rangle \equiv 0, \quad y_2 (s_0)= 0 \\
y_3 = \langle N, B \rangle \equiv 0, \quad y_3 (s_0)= 0 \\
y_4 = \langle T, T \rangle \equiv 1, \quad y_4 (s_0)= 1 \\
y_5 = \langle N, N \rangle \equiv 1, \quad y_5 (s_0)= 1 \\
y_6 = \langle B, B \rangle \equiv 1, \quad y_6 (s_0)= 1 
\end{split}
\end{equation}
Then by the uniqueness part we conclude that the set \(\{ T(s), N(s), B(s) \}\) remains orthonormal for every \(s\in I\).

Now, integrating each component of the vector \(T(s)\) we define the curve 
\[
\alpha(s) = \int T(r) dr. \]

Now, \(\alpha'(s) = T(s)\), and since \(T\) is a unit vector, \(\alpha\) is a unit speed curve and \(s\) is its arc-length. By Frenet's equations, \(T' = \kappa N\), and since \(N\) is a unit vector, \(\kappa\) is the curvature of \(\alpha\), and 
\(N\) is its principal normal. Since \(B\) is a unit normal perpendicular to \(T\) and \(N\), there is a smooth function  \(c(s)\) such that \(B = c T\times N\), and hence \(c(s)\) must be \(1\) or \(-1\) for all \(s\). Using the initial values condition we conclude that \(c(s) = 1\) for all \(s\). Then \(B\) is the binormal of \(\alpha\) and \(\tau\) its torsion.

Proof of uniqueness.

First recall that a linear transformation \(A: \mathbb{R}^3 \to \mathbb{R}^3\) is called orthogonal if it preserves the inner product:
\[ \langle Ax, Ay \rangle = \langle x, y \rangle,\quad x,y\in\mathbb{R}^3. \]
And the corresponding matrix is such that \(\det(A) = \pm 1\).

Now we show that the arc-length, the curvature and the torsion are invariant under rigid motions.
Let \(\alpha:I\to\mathbb{R}^3\) be a differentiable curve and \(M(x) = Ax + C\) a rigid motion. Then \(M \circ \alpha : I \to \mathbb{R}^3\) defines another curve, \(\bar{\alpha} (t) = A\alpha(t) + C\). Then
\[ \bar{\alpha}'(t) = A\alpha'(t), \]
and since it preserves inner product we have
\[ |\alpha'(t)|^2  = \langle \alpha'(t), \alpha'(t) \rangle = \langle A\alpha'(t), A\alpha'(t)\rangle = \langle \bar{\alpha}'(t) , \bar{\alpha}'(t) \rangle = |\bar{\alpha}'(t)|^2. \]
From the last observation we can verify that the arc-length is invariant under rigid transformations:
\[ s(t) = \int_{t_0}^{t} |\alpha'(r)| dr = \int_{t_0}^{t} |\bar{\alpha}'(r)| dr. \]
Then if \(\alpha\) is parameterised by arc-length, so is \(\bar{\alpha}\). Now, \(\alpha'' = \kappa N\), and under the rigid motion we have \(\bar{\alpha}'' = A\alpha''\). 
\[ \kappa^2 = \langle \alpha'',\alpha''\rangle = \langle A\alpha'',A\alpha''\rangle, \]
which implies that the curvature \(\kappa\) is
invariant under rigid motions. Similar argument shows that the torsion \(\tau\) is also invariant under rigid motions.

Suppose now that there are two curves \(\alpha\) and \(\bar{\alpha}\) such that for \(s\in I\):
\begin{equation*}
\begin{split}
\kappa(s) = \bar{\kappa}(s)\\
\tau(s) = \bar{\tau}(s)
\end{split}
\end{equation*}

Lets choose an initial condition. For \(s_0\in I\) let \(T_0,N_0,B_0\) the Frenet trihedron of the curve at \(\alpha(s_0)\) and \(\bar{T}_0,\bar{N}_0,\bar{B}_0\) the corresponding trihedron at \(\bar{\alpha}(s_0)\). By a proper translation and rotation, we can assume
\(\alpha(s_0) = \bar{\alpha}(s_0), T_0 = \bar{T}_0, N_0 = \bar{N}_0\) and \(B_0 = \bar{B}_0\). Each curve satisfies the Frenet's equations, then we have the following differential equaitons
\begin{equation*}
\begin{array}{ll}
T'(s) = \kappa(s) N(s). & \bar{T}'(s) = \bar{\kappa}(s) \bar{N}(s).\\
N'(s) = -\kappa(s) T(s) - \tau(s) B(s). &  \bar{N}'(s) = -\bar{\kappa}(s) \bar{T}(s) - \bar{\tau}(s) \bar{B}(s).\\
B'(s) = \tau(s) N(s) . & \bar{B}'(s) = \bar{\tau}(s) \bar{N}(s) .
\end{array}
\end{equation*}

Remeber that we have set the initial conditions \(\alpha(s_0) = \bar{\alpha}(s_0), T_0 = \bar{T}_0, N_0 = \bar{N}_0\) and \(B_0 = \bar{B}_0\).
Now, we want to show that \(|T(s) - \bar{T}(s)|\) vanishes for all \(s\in I\), and similar for \(|N(s) - \bar{N}(s)|\) and \(|B(s) - \bar{B}(s)|\). Note that
\begin{align*}
 \frac{1}{2}\frac{d}{ds} |T(s) - \bar{T}(s)|^2 & = \frac{1}{s}\frac{d}{ds} \langle T(s) - \bar{T}(s), T(s) - \bar{T}(s) \rangle \\ 
& = \langle T(s) - \bar{T}(s), T'(s) - \bar{T}'(s) \rangle \\
& = \kappa(s) \langle T(s) - \bar{T}(s), N(s) - \bar{N}(s) \rangle.
\end{align*}
In a similar way one shows that
\begin{align*}
\frac{1}{2}\frac{d}{ds} |B(s) - \bar{B}(s)|^2 &= \tau(s) \langle B(s) - \bar{B}(s), N(s) - \bar{N}(s) \rangle, \\
\frac{1}{2}\frac{d}{ds} |N(s) - \bar{N}(s)|^2 &= -\kappa(s) \langle N(s) - \bar{N}(s), T(s) - \bar{T}(s) \rangle  -\tau(s) \langle N(s) - \bar{N}(s), B(s) - \bar{B}(s) \rangle.
\end{align*}

Then the remarkable observation is that for any \(s\in I\)
\[ \frac{1}{2}\frac{d}{ds}\left[ |T(s) - \bar{T}(s)|^2 + |B(s) - \bar{B}(s)|^2 + |N(s) - \bar{N}(s)|^2 \right] = 0, \]
then the quantity is the constant \(0\). This shows that \(T(s) = \bar{T}(s), N(s) = \bar{N}(s)\) and \(B(s) = \bar{B}(s)\).
Finally  form
\[ \frac{d}{ds} \alpha(s) = T(s) = \bar{T}(s) = \frac{d}{ds} \bar{\alpha}(s), \]
it also follows that \((\alpha - \bar{\alpha})' \equiv 0\). Then \(\alpha(s) = \bar{\alpha}(s) + c\), for a constant vector \(c\in \mathbb{R}^3\). Bus since form our initial conditions
we are asuming \(\alpha(s_0) = \bar{\alpha}(s_0)\) then \(c=0\) and we conclude \(\alpha(s) = \bar{\alpha}(s)\) for all \(s\in I\).
\end{proof}


\begin{prop}
Let \(\alpha: I \to \mathbb{R}^3\) be a regular parameterised curve not necessarily by arc-length. Let \(s(t)\) the arc-length and denote by  \(t = t(s)\) be the inverse of the function \(s\). Then
\begin{enumerate}
\item Show that \[\frac{dt}{ds} = \frac{1}{|\alpha'|},\] and \[\frac{d^2t}{ds^2} = - \frac{\alpha'\bullet \alpha''}{|\alpha'|^4} \]
\item The curvature of \(\alpha\) at \(t\in I\) is \[ \kappa(t) = \frac{|\alpha' \times \alpha''|}{|\alpha'|^3}. \]
\item The torsion of \(\alpha\) at \(t \in I\) is \[ \tau(t) = -\frac{(\alpha' \times \alpha'')\bullet \alpha'''}{|\alpha' \times \alpha ''|^2} \]
\end{enumerate}
\end{prop}
\begin{proof}
The solution is left as an exercise. As a hint, here some of the identities that you may find on the way.
\begin{equation} \begin{split} T &=
\alpha' \frac{dt}{ds} =
\frac{\alpha'}{|\alpha'|}\\ \frac{dT}{ds}&=\frac{\alpha''}{|\alpha'|^2} -
\alpha' \frac{\alpha'\cdot\alpha''}{|\alpha'|^4}\\ \frac{d^2T}{ds^2}&=
\frac{\alpha'''}{|\alpha|^3} -
3\alpha''\frac{\alpha'\cdot\alpha''}{|\alpha|^5} +
\alpha'\frac{d^3t}{ds^3}. \end{split}
\end{equation} \begin{equation} T = \frac{\alpha'}{|\alpha'|},
\quad N = \frac{1}{k}T' , \quad B = T\times N
\end{equation} 
\end{proof}

\textbf{Remark} We were mainly studying curves in \(\mathbb{R}^3\) where the curvature was defined as a positive number \(\kappa >0\). In the case of curves on the plane \(\mathbb{R}^2\), it is possible to give a slightly different definition of curvature, where there is a sign associated to it. This is done by observing that, if a curve \(\alpha : I \to \mathbb{R}^2\) is 
parameterised by arc-length, and \(T = \alpha'(s)\), is the tangent vector, then there are only two possible unit vectors perpendicular to \(T\). One can then define the sign of the normal to be positive if \(N\) is obtained by rotating the tangen vector \(T\) anti-clockwise by \(\pi/2\).


\subsection{Global Theory of Curves}
\label{sec:org1ad5749}

Now we will study some global properties of Curves. Two classic results are: \textbf{the isoperimetric inequality} and the \textbf{Four Vertex Problem}.

In this course we will only focus on the former one. We will state the problem with curves and in the next section we  will generalise the questions to higher dimensions.


\subsection{The Isoperimetric Inequality}
\label{sec:org37a0f8e}

The isoperimetric inequality is still a thriving topic in modern mathematics. 

\begin{thm}
Let \(C\) be a simple closed curve in \(\mathbb{R}^2\) with length \(L\), and let \(A\) be the area of the region bounded by \(C\). Then we have
\[ L^2 - 4\pi A \geq 0,\]
and the equaltiy holds if and only if \(C\) is a circle.
\end{thm}

Last statement is related to the following questions:
\begin{itemize}
\item Among all closed curves of length \(L\) in the plane, how large can the enclosed area be?
\item Which curves enclose the largest possible area?
\item Among all regions in the plane with prescribed area \(A\), at least how long should the perimeter be?
\item Which figures realise the least perimeter?
\end{itemize}


The problem was known to the Greeks and they already knew that the equality was realised by the circle, but a rigorous proof took long time to appear. Only until 1870, K. Weierstrass gave examples of similar type of questions where a solution doesn't exists. In order to show the solvability of the isoperimetric problem he used arguments of minimising and maximising certain integral functional, developing then what we know as Calculus of Variations.

From Polya's Mathematics and plausible reasoning:

\begin{quote}
Dido, the fugitive daughter of a Tyrian king, arrived after many
adventures at the coast of Africa where she became later the founder of
Carthage and its first legendary queen. Dido started by purchasing, from
the natives a piece of land on the seashore "not larger than what an oxhide
can surround." She cut the oxhide into fine narrow strips of which she
made a very long string. And then Dido faced a geometric problem:
what shape of land should she surround with her string of given length in
order to obtain the maximum area?
\end{quote}

\begin{figure}[htbp]
\centering
\includegraphics[width=100pt]{./dido_pic01.png}
\caption{\label{fig:org5195658}Dido's problem along the shore}
\end{figure}


The following observation is a direct application of the isoperimetric inequality based on one of the many Jakob Steiner's ideas
\begin{prop}
The area of a polygon inscribed in a circle is greater than the area of any other polygon
with the same sides.
\end{prop}

\begin{figure}[htbp]
\centering
\includegraphics[width=100pt]{./dido_pic02.png}
\caption{\label{fig:org91eca1e}Steiner's Method}
\end{figure}



A nice collection of different proofs can be found in this article: \url{http://www.math.utah.edu/\~treiberg/isoperim/isop.pdf}
do Carmo's book on Curves and Surfaces presents Schmidt's proof of the isoperimetric inequality.
Another nice resource was posted in moodle, where a solution using Fourier series is discussed.

\section{The Isoperimetric Inequality in \(\mathbb{R}^n\).}
\label{sec:orgbccaa8a}

The proof that we will give is due to X. Cabré which involves the solution of a particular Partial Differential Equation, and the Moving Plane technique developed by Alexandrov, to obtain the result.


\begin{thm}
Let \(\omega_n\) denote the volume of the unit ball in \(\mathbb{R}^n\). If \(\Omega \subset\mathbb{R}^n\) is a bounded domain (open and connected), and \(\partial \Omega\) denotes its boundary, then
\[ |\partial\Omega| \geq n \, \omega_n^{\frac{1}{n}} |\Omega|^{1-\frac{1}{n}}, \]
and the equality is attained only when \(\partial \Omega\) is the sphere.
\end{thm}

\textbf{Remark} The notation \(|\partial \Omega|\) is used for the measure (area/volume) of the \((n-1)\) - dimensional surface, and similarly \(|\Omega|\) the volume of the \(n\) - dimensional domain.

\textbf{Exercise 1}. Show that 
\[ \omega_n = \frac{\pi^{\frac{n}{2}}}{\Gamma(\frac{n}{2} + 1)}, \]
where the Gamma function is given by
\[ \Gamma(s) = \int_{0}^{\infty} e^{-t}t^{s-1}dt. \]

\subsection{Moving planes}
\label{sec:orgaedc8ec}
\begin{mydef}
If \(\Omega \subset \mathbb{R}^n\) is a bounded domain (open and connected), and if \(u:\bar{\Omega} \to \mathbb{R}\) is a \(C^1\) function, we define the lower contact set as
\[ S = \{ x_0 \in \Omega \, | \, u(x) \geq u(x_0) + \nabla u(x_0) \cdot (x - x_0), \mbox{ for all } x\in \bar{\Omega} \}. \] 
\end{mydef}

Tasks:
\begin{itemize}
\item Recall the definition of the graph of a function.
\item Recall the definition of the Gradient of a function \(\nabla u\).
\item Given a surface defined by the graph of a function and a point \(p\) of the graph. What are the tangent vectors? What is the tangent hyperplane?
\item Given a surface defined by the graph of a function and a point \(p\) of the graph. What is one normal vector to the surface at the point?
\item What is the equation of the hyperplane of the graph at a point?
\end{itemize}

Consider a hyperplane moving parallel to itself, it is easy to see that if the first point of contact is an interior point of \(\Omega\), then the plane becomes the tangent at that point:

\begin{prop}
If by translating a plane moving parallel to itself, the first contact point of the plane with the graph of the function \(u\) has a first coordinate \(x_0\in \Omega\), this hyperplane is such that
satisfies the inequality
\[ u(x) \geq u(x_0) + m \cdot (x - x_0), \]
for some \(m\in \mathbb{R}^n\). Then \(m = \nabla u(x_0)\). 
\end{prop}

Task:
\begin{itemize}
\item What is a critical point of a function?
\item What is the Hessian of a function \(u:\mathbb{R}^n\to \mathbb{R}\)?
\item How determine if a critical point is a minimum or a maximum?
\item What is a convex/concave function?
\item What is the Taylor expansion of a function?
\end{itemize}


\begin{prop}
If the function is twice differentiable and \(x_0\in S\), then \(D^2u(x_0)\) is a symmetric and positive definite matrix.
\end{prop}


\subsection{Partial Differential Equations: a Neumann Problem}
\label{sec:orgdb70829}

In order to understand ponts in \(S\) that are in the boundary of our domain \(\Omega\), we introduce the following Partial Differential Equation:
\begin{equation}
\left\{ \begin{array}{cccr}
\Delta u & = & \frac{|\partial \Omega|}{|\Omega|} & \mbox{in } \Omega \\
\dfrac{\partial u}{\partial \nu} & = & 1 & \mbox{on } \partial{\Omega} \\
\end{array} \right.
\end{equation}

Last expression is an example of a Neumann problem, where \(\nu\) denotes the outer unit vector at boundary points.


Task:
\begin{itemize}
\item Recall what is the Laplace operator \(\Delta\).
\item Recall what is the normal derivative \(\frac{\partial u }{\nu}\).
\end{itemize}

\begin{prop}
If by translating a plane moving parallel to itself, the first contact point of the plane with the graph of the function \(u\) has a first coordinate \(x_0\in \partial\Omega\), then
\[ m \cdot \nu(x_0) \geq \nabla u(x_0) \cdot \nu(x_0). \]
Where the plane is assume to satisfy for \(x_0\in \partial\Omega\) and any \(x\in \bar{\Omega}\)
\[ u(x) \geq u(x_0) + m \cdot (x - x_0). \]
\end{prop}

\begin{thm}
Let \(B_1(0)\) be the unit ball in \(\mathbb{R}^n\) with centre at the origin and \(u:\Omega\subset \mathbb{R}^n \to \mathbb{R}\) is a solution to our Neumann problem. Consider the  lower contact set of \(u\), \(S\),  and let \(\nabla u (S) = \{ \nabla (x) \in \mathbb{R}^n \, | \, x \in S\}\). Then the following holds
\[ B_1(0) \subset \nabla u(S). \]
\end{thm}

\subsection{Proof of the Isoperimetric Inequality}
\label{sec:org1c5c7f3}

Using the last theorem, the proof of the isoperimetric inequality follows from
\begin{equation}
\begin{split}
\omega_n = |B| = \int_B dx & \leq \int_{\nabla u (S)} dx \leq \int_{S} \text{det}(D^2 u) dx  \\  
& \leq \int_{\Omega} \text{det}(D^2 u) dx 
\leq \int_{\Omega} \left( \frac{\text{tr}(D^2 u)}{n}\right)^n dx =
\int_{\Omega} \left( \frac{\Delta u}{n}\right)^n dx \\
 & = \int_\Omega \left( \frac{|\partial\Omega|}{n|\Omega|}\right)^n dx =
 \frac{|\partial\Omega|^n}{n^n|\Omega|^{n-1}} .
\end{split}
\end{equation}

Task.
\begin{itemize}
\item Justify every \(\leq\) and \(=\) in last expression.
\item Recall the AM-GM (or Newtons') inequalities \[ \frac{x_{1}+x_{2}+\cdots +x_{n}}{n}\geq \sqrt[n]{x_{1}\cdot x_{2}\cdots x_{n}} \]
\item For a matrix \(A\) of size \(n\times n\), the determinant of \(A\) equals the product of its eigenvalues.
\item If a function \(f\) is such that all partial derivatives vanish at all poinst of an open set, then \(f\) is constant.
\end{itemize}


\subsection{Proof of the equality case}
\label{sec:org3c1babf}

If the equality holds:
\begin{itemize}
\item Note that \(|S| = |\Omega|\).
\item The eigenvalues of \(D^2u(x)\) are all equal to the constant \(\left(\omega_n / |\Omega|\right)^{1/n}\).
\item \(B_1(0) \subset \nabla u(S)\) in the equality case implies \(B_1(0)\) is dense in \(\nabla u (\Omega)\).
\item Since \(|\nabla u| \leq 1\) in \(\bar{\Omega}\) and \(|\nabla u| \geq |\nabla u \cdot \nu | = 1\) then \(u\) is constant on the boundary \(\partial \Omega\).
\item The function \(u\) solves the Neumann problem, and its unique up to a constant, then  we can  assume after translation that \(u(x) = 0\) on \(\partial \Omega\).
\item Pick \(x_0 \in \Omega\) be the minimum of \(u\) and consider the largest possible ball \(B(x_0)\) in \(\Omega\) with centre at \(x_0\).
\item Apply the mean value theorem: if \(x\in B(x_0)\), there is some \(\xi\) in the line segment \((1-t)x_0 + tx\), \(0 \leq t \leq 1\) such that \[ u(x) = u (x_0) + \nabla u(x_0) \cdot (x - x_0) + \frac{1}{2} (x- x_0)^T D^2 u(\xi) (x - x_0) = u(x_0) + \frac{\lambda}{2} |x - x_0|^2 .\]
\item Pick a point \(x \in \partial B \cap \partial \Omega\) and conclude that \(\partial \Omega = \partial B(x_0)\).
\end{itemize}


\subsection{Conclusion.}
\label{sec:orgdf71926}

The Isoperimetric Inequality and related problems are advanced topics. 
It is usually part of the introduction of a branch of mathematics called the Calculus of Variations, where the problem of optimization (finding maximum and minimum) takes place in infinite dimensional spaces.
The proof we studied here, uses only concepts from Calculus in several variables. This is a very active topic of research since one can keep asking question like:\\
Does the Isoperimetric inequality holds in spaces other than \(\mathbb{R}^n\)?\\
What if our definition of \emph{volume} and \emph{area} are different?

On the geometric side, Alexandrov’s idea of moving planes has helped to solve many questions regarding surfaces of constant mean curvature.





\section{Mechanics}
\label{sec:org48fe45c}

We are coming back to the theory of curves in the space, and we will use calculus along curves toggether with Newton's law to determine the Laws that Kepler establised to determine the planetary motinon around the Sun.

We will start with some useful definitinons from physics. In this section we will emphasize whether a quantity is a scalar or a vector (usually in \(\mathbb{R}^3\)) by wirting vectors in bold face letter: \(\mathbf{a},\mathbf{b},\mathbf{A},\mathbf{r},\ldots\). 

Here we will be studying the movement of the particles in the space. Its position in space also depends on the time parameter \(t\), and this poisition vector  will be denoted by \(\mathbf{r}(t)\).

\begin{mydef}
\textbf{The position vector}. It is a maping \(\mathbf{r}:I \to \mathbb{R}^3\), where \(I\subseteq \mathbb{R}\) is called the time interval, and for this we will use the parameter \(t\). We will assume \(\mathbf{r}\) as smooth as needed in the computations (at least \(C^2\)). It can also be written incoordinates as \(\mathbf{r}(t) = \left(r_1(t), r_2(t), r_3(t) \right)\).

\textbf{The velocity vector}. The first derivative with respect to the parameter \(t\) is called the velocity vector: \(\mathbf{r}'(t) = \frac{d\mathbf{r}}{dt}(t) = \left(\frac{dr_1}{dt}(t),\frac{dr_2}{dt}(t),\frac{dr_3}{dt}(t)\right)\)

\textbf{The acceleration vector}. The second derivatives with respect to the parameter \(t\) is called the acceleration vector: \(\mathbf{r}''(t)\).
\end{mydef}

\begin{mydef}
\textbf{Newton's Second Law of motion}.  Let \(m\) be the mass of a particle with position vector \(\bf{r}(t)\). Then the \textbf{force} acting on the particle is proportional to the acceleration: \[ \mathbf{F}(t) = m\, \mathbf{a}(t) = m\, \mathbf{r}''(t). \]

\textbf{(Linear) Momentum}. Let \(m\) be the mass of a particle with position vector \(\bf{r}(t)\). Then the \textbf{momentum} is defined as the mass times the velocity: \[ \mathbf{p}(t)=  m\, \mathbf{{v}}(t) = m\, \mathbf{r}'(t). \]
\end{mydef}


Note that \emph{the time derivative of the momentum of an object is the net force on the object}: \(\mathbf{p}'(t) = F(t)\). If the net force on an object is continually zero,
then we say that in this case, the momentum of the object is conserved.

\begin{mydef}
\textbf{Angular momentum}. Let \(\mathbf{r}(t)\) be the position vector of a moving particle of mass \(m\). Then the angluar momentum about the origin is defined as \[ \mathbf{L}(t) = \mathbf{r}(t) \times m\,\mathbf{v}(t). \]


\textbf{Torque}. The torque measures how the angular momentun changes with respecto to time. \[ \mathbf{\tau}(t) = \mathbf{L}'(t) = \mathbf{r}(t) \times \mathbf{F}(t). \]

\textbf{Radial force} If a force \(\mathbf{F}(t)\) is acting on a particle is parallel to its position vector \(\mathbf{r}(t)\), then \(\mathbf{F}\) is called \emph{radial force} or \emph{central force}. Note that for a radial force we always have \(\mathbf{\tau}(t) = 0\).
\end{mydef}

Whe say that the angular momentum is conserved if the torque equals zero. And we also have the following conservation law: 
\emph{If the net torque on an object is continually zero, then the angular momentum of the object is conserved.} A nice explanation of the conservation of angular momentum can be found in this \href{https://www.youtube.com/watch?v=8I4ii1xEeG0}{link}.


\begin{thm}
If an object moves under a central force and has constant angular momentum
\(\mathbf{L}\) different from zero, then:
\begin{enumerate}
\item The object is confined to the plane that passes through the origin and is perpendicular to \(\mathbf{L}\)..
\item The radius vector of the object sweeps out equal areas in equal times.
\end{enumerate}
\end{thm}

\subsection{Kepler's laws of planetary motion.}
\label{sec:org8175a37}

\begin{itemize}
\item Each planet moves in a plane, not in a circle, but in an elliptical orbit with the sun at one focus.
\item The radius vector from the sun to the planet sweeps out equal areas in equal times.
\item The square of the period of the motion varies directly as the cube of the major semiaxis, and the constant of proportionality is the same for all the planets.
\end{itemize}

\begin{thm}
\textbf{Newton's law of universal gravitation}. Every particle attracts every other particle in the universe with a force that is directly proportional to the product of their masses and inversely proportional to the square of the distance between their centers. In vector notation this can be written as \[ F(t) = -G \frac{m \, M}{r^3} \mathbf{r}(t). \]
\end{thm}

In this section, we will use Newton's gravity law to obtain Kepler's law about planetary motion.


\subsubsection{The Force is radial and the Angular momentum is constant.}
\label{sec:orge5fce7e}

Place the origing of the poisition vector of the planet at the Sun. Since we will described the movement of the planet with respect to the sun, we will be only considering 
the force interacting between these two objects. Form the Newton'w Law, we see that the force is parallel to the position vector. Then according to our definition, the force
\textbf{F} is a \emph{radial force}. This implies that the torque \(\tau = 0\). If the torque is zero, then then \emph{angular momentum} \(\mathbf{L}(t)\) is constant (independent of \(t\)).
Note that from the definition of angular momentum we have
\[ |\mathbf{L}(t)| = |\mathbf{r}(t) \times m \mathbf{v}(t)| = m |\mathbf{r}(t)||\mathbf{v}(t)| \cos\theta \]

All the physical evidence shows that
\begin{itemize}
\item The mass of the planet is not zero: \(m\neq 0\).
\item The planets are moving then \(|\mathbf{v}(t)| \neq 0\)
\item The distance of the planet from the Sun is poisitive, then \(|\mathbf{r}(t)| \neq 0\).
\end{itemize}

All this implies that the \emph{Angular Mumentum} \(\mathbf{L}(t) = \mathbf{L} \neq \mathbf{0}\).

\subsubsection{All the movement happens on a plane}
\label{sec:org63b1c15}

Since all the position vectors \(\mathbf{r}(t)\) are perpendicular to a constant vector \(\mathbf{L}\), then  \(\mathbf{L}\cdot \left(\mathbf{r}(t) - \mathbf{r}(t_0)\right) = 0\). Then all the movement is restricted to a plane.


\subsubsection{The radial vector sweeps out equal areas in equal times}
\label{sec:org7d2e27e}

We can assume all the movement is restricted to the \(xy\) - plane. We can write the position vector \(\mathbf{r}(t)\) in polar coordinates \((r(t), \theta(t)) = (r(t)\cos\theta(t), r(t)\sin\theta(t), 0)\). We define the Area function \(A(t)\) as the circular sector area
\[ A(t) = \frac{1}{2} r(t)^2 \theta(t) .\]

\section{Surfaces in \(\mathbb{R}^3\)}
\label{sec:orgcfb3ba8}

\section{The Inverse Function Theorem.}
\label{sec:orgc86d67c}
\begin{thm}
Suppose that \(f:\mathbb{R}^n \to \mathbb{R}^n\) is a continuously differentiable in an open set \(U\subset \mathbb{R}^n\) containing a point \(a\in U\), and suppose \(\det(Df_a) \neq 0\). Then there are open sets \(V,W\subset\mathbb{R}^n\), 
\end{thm}

\section{The Implicit function theorem}
\label{sec:orga8fb1fc}


\section{Multiple Integration: surface areas, volumes.}
\label{sec:org8efc061}

\section{Gradient, Divergence and Curl. Stokes’ Theorem, the Flux of a Vector Field}
\label{sec:orga3915cd}
\section{Tensors and their properties. Differential forms.}
\label{sec:org71f9e18}

\subsection{Multilinear maps}
\label{sec:orge839fa4}
\begin{itemize}
\item A function \(T:V^k = V\times\cdots\times V \to \mathbb{R}\) that is \textbf{multilinear} at each entry is called \textbf{k-tensor} on \(V\), denoted by \(\mathcal{T}^k(V)\).
\item The set \(\mathcal{T}^k(V)\) is a vector space over \(\mathbb{R}\).
\item The tensor product \(\otimes\) takes any pair \(S\in \mathcal{T}^k(V)\) and \(T\in \mathcal{T}^l(V)\) to the tensor \(\left(S \otimes T\right)\in \mathcal{T}^{k+l}(V)\). In general \(S\otimes T \neq T\otimes S\). Some properties of \(\otimes\): exercise.
\begin{itemize}
\item \((S + T) \otimes U  = S \otimes U + T \otimes U\)
\item \((S \otimes ( T + U)  = S \otimes T + S \otimes U\)
\item \((\alpha S) \otimes T = S\otimes (\alpha T) = \alpha (S \otimes T)\).
\end{itemize}
\item Note that \(V^* = \mathcal{T}^1(V)\).
\item Let \(\{ x_1, \ldots, x_n \}\) be a basis for \(V\). Then the corresponding dual basis \(\{ \varphi_1, \ldots, \varphi_n\}\) is a basis for \(\mathcal{T}^1(V)\).
\item The set of all k-tensor products \(\{ \varphi_{i_1} \otimes \cdots \otimes \varphi_{i_k} \}\) with \(1\leq i_1, i_2,\ldots,i_k \leq n\) is a basis for \(\mathcal{T}^k(V)\) (consisting on \(n^k\) elements).
\item If \(f:V\to W\) is linear, then \(f^*: \mathcal{T}^k(W) \to \mathcal{T}^k(V)\) defined by \(f^*T(v_1, \ldots, v_k) = T(f(v_1),\ldots,f(v_k))\). It holds \(f^*S \otimes f^*T\).
\item About the inner product as a symmetric tensor. If \(A = a^i\partial_i\) and \(B= b^j\partial_j\) two tangent vectors to a surface \(S\) at a point \(p\), i.e., \(A,B\in T_pS\). Then the metric tensor \(g = g_{ij}dx^i\otimes dx^j\) is such that \[ g(A,B) = a^ib^jg_{ij} .\]
\item Let \(\alpha: [a,b] \to S\) a regular curve on a surface \(S\). Then the tangent vectors \(\dot{\alpha}(t) \in T_{\alpha(t)}S\), and the metric \(g\) is used to define the length of a curve, note that we can write \(\dot{\alpha}(t) = \dot{\alpha}^i\partial_i\) as \[ L(\alpha) = \int_{a}^{b} \sqrt{g_{\alpha(t)}(\dot{\alpha}(t),\dot{\alpha}(t))} dt = \int_{a}^{b} \sqrt{g_{ij}\dot{\alpha}^i\dot{\alpha}^j} dt. \]
\item We denote the inverse of the metric \(g_{ij}\) by \(g^{ij}\), and we then have \(g^{ik}g_{kj} = \delta_{ij}\).
\item If \(f:S\to \mathbb{R}\) is a differentiable function in a surface \(S\), the gradient is given by \(\nabla f = g^{ij}\partial_if \, \partial_j\).
\item On the other hand, if \(f:S\to \mathbb{R}\) is a differentiable function in a surface \(S\) then \(df = \partial_i f dx^{i}\).
\begin{itemize}
\item Show that if \(A = a^i\partial_i\) then \(df(A) = g( \nabla f, A)\).
\item \(df\) is a one tensor, but it is also a one form. Forms will be define below.
\end{itemize}
\item Any finite dimensional vector space with inner product have an isometry \(f:V\to \mathbb{R}^n\) with the Euclidean space with usual inner product. (Inner product (finite dimensional) spaces are isometric)
\item About the determinant as an anti-symmetric tensor. Do you remember any definition of the determinant? Do you remember some of its properties?
\item Subspace of alternating k-tensor \(\Lambda^k(V) \subset \mathcal{T}^k(V)\).
\item Definition of the sign of a permutation. Permutations are bijections from a set \(S\) onto itself. All permutations of a set with \(n\) elements form a symmetric group, denoted \(S_n\), where the group operation is function composition. Thus for any permutations in the group \(S_{n}\), the four group axioms hold:
\begin{itemize}
\item Closure
\item Associativity
\item Identity
\item Invertibility
\item In general, composition of two permutations is not commutative.
\item Every permutation of a finite set can be expressed as the product of transpositions. Although many such expressions for a given permutation may exist, either they all contain an even or an odd number of transpositions. Thus all permutations can be classified as even or odd depending on this number.
\end{itemize}
\item Definition of \(\mbox{Alt}:\mathcal{T}^k(V) \to \Lambda^k(V)\).  The number \(k!\) is the number of ways we can rearrange \(k\) things into a new order. \[ \mbox{Alt}(T)(v_1,\ldots,v_k)  = \frac{1}{k!}\sum_{\sigma\in S_k} \mbox{sgn} \sigma \, T(v_{\sigma(1)},\ldots, v_{\sigma(1)}) \]
\item Note \(\left.\mbox{Alt}\right|_{\Lambda^k(V)} = \mbox{Id}\), and \(\mbox{Alt}^2 = Id\).
\item Definition of the wedge product. Some properties of \(\wedge\): exercise. Associativity is a bit harder to prove.
\begin{itemize}
\item If \(\omega\in \Lambda^k(V)\) and \(\eta\in \Lambda^l(V)\) then \(\omega \wedge \eta \in \Lambda^{k+l}(V)\) given by \[ \omega \wedge \eta = \frac{(k+l)!}{k! \, l!} \mbox{Alt} (\omega \otimes \eta). \]
\item \((\omega_1 + \omega_2) \wedge \eta = (\omega_1 \wedge \eta) + (\omega_2 \wedge \eta)\).
\item \(\omega \wedge (\eta_1 + \eta_2)  = (\omega \wedge \eta_1) + (\omega \wedge \eta_2)\).
\item \(\alpha\omega \wedge \eta = \omega \wedge \alpha\eta = \alpha(\omega \wedge \eta)\).
\item \(\omega \wedge \eta = (-1)^{kl}\eta \wedge \omega\).
\item \(f^*(\omega\wedge \eta) = f^*(\omega) \wedge f^*(\eta)\).
\end{itemize}
\item Theorem:
\begin{itemize}
\item If \(S\in \mathcal{T}^k(V)\), \(T\in \mathcal{T}^l(V)\) with \(\mbox{Alt}(S) = 0\) then \(\mbox{Alt}(S\otimes T) = \mbox{Alt}(T\otimes S) = 0\).
\item \(\mbox{Alt}(\mbox{Alt}(\omega\otimes \eta) \otimes \gamma) = \mbox{Alt}(\omega \otimes \eta \otimes \gamma) = \mbox{Alt}(\omega\otimes \mbox{Alt}(\eta \otimes \gamma))\).
\item \((\omega \wedge \eta) \wedge \gamma = \omega \wedge (\eta \wedge \gamma)\).
\end{itemize}
\item Dimension of \(\Lambda^k(V)\) equals \({n\choose k}\).
\item Theorem. Let \(v_1,\ldots, v_n\in V\) a basis for \(V\) and let \(\omega \in \Lambda^n(V)\). If \(w_i = \sum_{j}a_{ij}v_j\) are \(n\) vectors in \(V\), then \[ \omega(w_1, \ldots, w_n) = \det(a_{ij}) \, \omega(v_1,\ldots,v_n).\]
\item Orientation.
\item The Volume element. Suppose that an inner product \(g\) in \(V\) is given. If \(\{v_i\}\) and \(\{w_i\}\) are two bases which are orthonormal with respect to T, and the matrix \(A = (a_{ij})\) is the change of basis matrix then \[ \delta_{ij} = g(w_i,w_j) = a_{ik}a_{jl}g(v_k,v_l) = a_{ik}a_{jl}\delta_{kl} = a_{ik}a_{jk}, \] which shows that \(A\,A^T = I\). hence \(\det(A) = \pm 1\), which implies that if \(\omega(v_1,\ldots,v_n) = \pm 1\), then \(\omega(w_1,\ldots,w_n) = \pm 1\). The unique form \(w\) such that \(\omega(v_1,\ldots,v_n) = 1\), is called the \textbf{volume element} or \textbf{volume form} of \(V\), determined by the inner product \(g\) and an onrientation.
\item The Pullback. If we consider now a differentiable function \(f: \mathbb{R}^n\to\mathbb{R}^m\) we have a linear transformation \(Df_p: \mathbb{R}^n \to \mathbb{R}^m\). This induces a linear transformation \(f^*:\Lambda^k(\mathbb{R}^m) \to \Lambda^k(\mathbb{R}^{n})\) by taking the form \(\omega\) at the point \(f(p)\in \mathbb{R}^m\) to  the form \((f^*\omega)\) at \(p\in\mathbb{R}^n\). If \(v_1, \ldots, v_k \in \mathbb{R}^n\) note that \(Df_p(v_1), \ldots, Df_p(v_k) \in \mathbb{R}^m\) and hence \[ (f^*\omega)(v_1,\ldots,v_k) = \omega(Df_p(v_1),\ldots,Df_p(v_k)).\]
\end{itemize}

\subsection{Differentiable Forms}
\label{sec:org2361002}
\begin{itemize}
\item Recall the notion (definition) of a vector field.
\item The map \(\omega : \mathbb{R}^n \to \Lambda^k(\mathbb{R}^n)\).
\item \(0-\) forms.
\item \(1-\) forms.
\item Exterior derivative \(d\). If \(\omega \in \Lambda^{k}(V)\)
\item Closed forms
\item Exact forms
\item Characterisation of closed 1-forms in \(\mathbb{R}^2\).
\item Poincaré Lemma.
\end{itemize}

\textbf{Poincaré Lemma}. Let \(A\subset\mathbb{R}^n\) be open starshaped with respect to the origin. Then every closed form on \(A\) is exact.
\begin{proof}
Let \(\omega\) a closed \(l\) form:
\begin{equation}
\omega = \sum_{i_i < \cdots < i_l} \omega_{i_i,\ldots,i_l} dx^{i_1} \wedge \cdots \wedge dx^{i_l}.
\end{equation}

Its exterior derivative is the \(l\) form given by
\begin{equation}
d\,\omega = \sum_{i_i < \cdots < i_l} \sum_{j=i}^n D_j (\omega_{i_i,\ldots,i_l}) dx^{j}\wedge dx^{i_1} \wedge \cdots \wedge dx^{i_l}.
\end{equation}


Define \(I\omega\) as the \((l-1)\) -form 
\begin{equation}
I\omega = \sum_{i_i < \cdots < i_l} \sum_{r=1}^l (-1)^{r-1}\int_{0}^1 t^{l-1}\omega_{i_i,\ldots,i_l}(tx)dt\,\, x^{i_{r}}\, dx^{i_1}  \wedge \cdots\wedge \hat{dx^{i_r}} \wedge \cdots\wedge dx^{i_l}.
\end{equation}

Note that in last expression \(x^{i_r}\) stands for the projection function.

Apply the exterior derivative \(d\) to \(I(\omega)\), we have
\begin{equation}
d( I\,\omega) = l \, \sum_{i_1 < \cdots i_l} \int_{0}^{1}t^{l-1} \omega_{i_1,\ldots,i_l}(tx) dt \, dx^{i_1} \wedge \cdots \wedge dx^{i_l} +  \sum_{i_1 < \cdots < i_l}\sum_{r=1}^l \sum_{j=1}^n (-1)^{r-1} \int_{0}^{1}t^{l} D_j\omega_{i_1,\ldots,i_l}(tx) dt \,x^{i_r}\, dx^{j}\wedge dx^{i_1} \wedge \cdots \hat{dx^{i_r}}\wedge \cdots dx^{i_l} 
\end{equation}


Apply \(I\) to \(d\,\omega\) to get an \(l\) -form
\begin{equation}
I( d\,\omega) = \sum_{i_i < \cdots < i_l} \sum_{j=1}^n  \int_{0}^{1} t^l\,D_j(\omega_{i_i,\ldots,i_l})(tx) dt\, x^{j}\, dx^{i_1} \wedge \cdots \wedge dx^{i_l}
- \sum_{i_i < \cdots < i_l}\sum_{j=1}^n\sum_{r=1}^l (-1)^{r-1}\int_{0}^1 t^{l}D_{j}\omega_{i_i,\ldots,i_l}(tx)dt\,\, x^{i_{r}} dx^j\wedge dx^{i_1}  \wedge \cdots\wedge \hat{dx^{i_r}} \wedge \cdots\wedge dx^{i_l}.
\end{equation}
\end{proof}
\end{document}